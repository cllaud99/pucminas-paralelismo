# Trabalho: Fundamentos de Python â€” Paralelismo  
**PUC Minas - Engenharia de Dados**  
**Disciplina:** Fundamentos de Python  
**Aluno:** ClÃ¡udio Pontes  

---

### ğŸ“Œ DescriÃ§Ã£o  
Este projeto foi desenvolvido como parte da disciplina de Fundamentos de Python com foco em tÃ©cnicas de paralelismo e concorrÃªncia. O objetivo Ã© demonstrar o uso de threads e processos para acelerar tarefas tÃ­picas de Engenharia de Dados, como ingestÃ£o de arquivos, chamadas a APIs, transformaÃ§Ã£o de dados, simulaÃ§Ãµes de ETL e benchmarking de performance.

O projeto estÃ¡ dividido em trÃªs nÃ­veis de complexidade:

- **NÃ­vel 1 â€” Fundamentos com foco em I/O**  
- **NÃ­vel 2 â€” Processamento CPU-bound com dados**  
- **NÃ­vel 3 â€” CenÃ¡rios avanÃ§ados e integraÃ§Ãµes**

---

### ğŸ§  ExercÃ­cios implementados  
Cada nÃ­vel contÃ©m 5 exercÃ­cios numerados conforme a proposta da disciplina:

**level_01/**  
1. Crawler concorrente de APIs usando threading.Thread para coletar dados de mÃºltiplos endpoints.

2. IngestÃ£o paralela de vÃ¡rios arquivos CSV com ThreadPoolExecutor e Pandas.

3. Monitoramento simultÃ¢neo de tempo de resposta de diversas URLs, com gravaÃ§Ã£o dos resultados.

4. SimulaÃ§Ã£o de downloads concorrentes usando ThreadPoolExecutor e delays artificiais.

5. Consulta paralela simulada a mÃºltiplas bases de dados com threads, gerando resumos independentes.

**level_02/**

6. TransformaÃ§Ã£o pesada de dados usando ProcessPoolExecutor para operaÃ§Ãµes CPU-bound.
7. AplicaÃ§Ã£o paralela de funÃ§Ãµes complexas em partes de DataFrames com processos.
8. ConversÃ£o paralela de arquivos Parquet para CSV, processando cada arquivo individualmente.
9. CÃ¡lculo paralelo de agregaÃ§Ãµes estatÃ­sticas (soma, mÃ©dia, desvio) em grandes DataFrames.
10. Pipeline multiprocessamento: transformaÃ§Ã£o em um processo e persistÃªncia em outro, usando pipes ou queues.

**level_03/**

11. ETL paralelo por partiÃ§Ã£o de dados, simulando processamento distribuÃ­do em Data Lake.
12. ExtraÃ§Ã£o concorrente de dados paginados via API, unindo resultados em paralelo com threads.
13. SimulaÃ§Ã£o de mÃºltiplos produtores e consumidores usando queue.Queue para leitura e escrita concorrentes.
14. Benchmark comparativo entre pipeline serial e paralela em trÃªs etapas (ingestÃ£o, transformaÃ§Ã£o, escrita).
15. Sistema paralelizado de alertas baseado em monitoramento de logs e detecÃ§Ã£o de padrÃµes crÃ­ticos.

---

### ğŸ“ Estrutura de pastas  
```markdown
.
â”œâ”€â”€ README.md
â”œâ”€â”€ data/ # Dados de entrada e saÃ­da
â”œâ”€â”€ logs/ # Arquivos de log gerados pelos exercÃ­cios
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â””â”€â”€ src/
    â”œâ”€â”€ apis/
    â”‚   â””â”€â”€ weather_api.py
    â”œâ”€â”€ level_01/
    â”‚   â””â”€â”€ exercice_01.py ... exercice_05.py
    â”œâ”€â”€ level_02/
    â”‚   â””â”€â”€ exercice_06.py ... exercice_10.py
    â”œâ”€â”€ level_03/
    â”‚   â””â”€â”€ exercice_11.py ... exercice_15.py
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ faker_create_datasets.py
    â”‚   â”œâ”€â”€ simulated_api.py
    â”‚   â”œâ”€â”€ compare_times.py
    â”‚   â””â”€â”€ log_decorator.py
    â””â”€â”€ main.py # Script principal para orquestrar todos os nÃ­veis
```

---

### â–¶ï¸ Como executar  
Clone o repositÃ³rio:

```bash
git clone https://github.com/seu-usuario/pucminas-paralelismo.git
cd pucminas-paralelismo
```

Instale as dependÃªncias (via Poetry):

```bash
poetry install
```

Execute o projeto:

```bash
poetry run python src/main.py
```

Este comando:

- Gera datasets simulados com faker_create_datasets.py  
- Inicia uma API local simulada (FastAPI)  
- Executa todos os exercÃ­cios dos trÃªs nÃ­veis em sequÃªncia  

---

### ğŸ§ª DependÃªncias principais  
- threading, concurrent.futures  
- pandas, pyarrow  
- faker, requests, loguru  
- FastAPI, Uvicorn, aiomultiprocess  

As dependÃªncias estÃ£o especificadas no arquivo **pyproject.toml**.

---

### âœ… Task de formataÃ§Ã£o  
```bash
poetry run task format
```

Executa o isort e black para manter o cÃ³digo limpo e padronizado.

---

### ğŸŒ API Simulada  
Durante a execuÃ§Ã£o, uma API FastAPI Ã© iniciada localmente na porta 8000, simulando endpoints para exercÃ­cios com chamadas HTTP concorrentes.

---

### ğŸ“Œ ObservaÃ§Ãµes  
- Todos os exercÃ­cios foram projetados com foco em boas prÃ¡ticas de Engenharia de Dados.  
- O projeto utiliza logs para acompanhamento e debug.  
- SimulaÃ§Ãµes foram aplicadas para representar cenÃ¡rios reais de ETL e monitoramento.
